{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터 불러오기\n",
    "\n",
    "train_path1 = './augment data/augmented_inserted_text_data.csv' # 필요에 따라 변경하세요.\n",
    "train_path2 = './augment data/augmented_replaced_text_data.csv' # 필요에 따라 변경하세요.\n",
    "train_path3 = './augment data/raw_data.csv' # 필요에 따라 변경하세요.\n",
    "test_path = './data/test.csv' # 필요에 따라 변경하세요.\n",
    "train_normal_data_path = './data/일반대화 합성데이터(GPT-4o, AIhub 참고).csv'\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df1 = load_data(train_path1)\n",
    "train_df2 = load_data(train_path2)\n",
    "train_df3 = load_data(train_path3)\n",
    "test_df = load_data(test_path)\n",
    "normal_df = load_data(train_normal_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4846, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3878, 4), (484, 4), (484, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df3 = train_df3.drop_duplicates(subset=['conversation'])\n",
    "train_df3 = train_df3.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "val_df = train_df3.iloc[:4846//10, ]\n",
    "test_df = train_df3.iloc[4846//10:4846//10*2, ]\n",
    "train_df3 = train_df3.iloc[4846//10*2:, ]\n",
    "train_df3.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13548, 5), (484, 4), (484, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data 와 normal 데이터 합치기\n",
    "def concat_train_normal(df_list):\n",
    "    train_df = pd.concat(df_list, ignore_index=True)\n",
    "#     train_df.drop(['idx'], axis=1, inplace=True)\n",
    "    train_df.reset_index(inplace=True)\n",
    "\n",
    "    return train_df\n",
    "\n",
    "df_list = [train_df1, train_df2, train_df3]\n",
    "train_df = concat_train_normal(df_list)\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>class</th>\n",
       "      <th>class_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>왜 지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면...</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>길동경찰서입니다. 9시 40분 마트에 폭발물을 하나 더 설치할거다.? 네? 똑바로 ...</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 키 작은 남자는 첨봤어. 그만해. 니들 놀리는거 진...</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>어이 거기 예?? 너 말이야 너. 너 이리 오라고 무슨 일. 너 옷 좋아보인다? 얘...</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>저기요 혹시 날이 너무 많이 뜨겁잖아요? 저희 회사에서 지금 이 선크림 파는데 한 ...</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        conversation      class  class_encoded\n",
       "0  왜 지금 너 스스로를 죽여달라고 애원하는 것인가? 아닙니다. 죄송합니다. 죽을 거면...      협박 대화              0\n",
       "1  길동경찰서입니다. 9시 40분 마트에 폭발물을 하나 더 설치할거다.? 네? 똑바로 ...      협박 대화              0\n",
       "2  너 되게 귀여운거 알지? 나보다 키 작은 남자는 첨봤어. 그만해. 니들 놀리는거 진...  기타 괴롭힘 대화              3\n",
       "3  어이 거기 예?? 너 말이야 너. 너 이리 오라고 무슨 일. 너 옷 좋아보인다? 얘...      갈취 대화              1\n",
       "4  저기요 혹시 날이 너무 많이 뜨겁잖아요? 저희 회사에서 지금 이 선크림 파는데 한 ...      갈취 대화              1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[['conversation', 'class', 'class_encoded']]\n",
    "val_df = val_df[['conversation', 'class', 'class_encoded']]\n",
    "test_df = test_df[['conversation', 'class', 'class_encoded']]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13548, 3), (484, 3), (484, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 개행 문자(\"\\n\")를 공백으로 변환\n",
    "  sentence = re.sub(r\"\\n\", \" \", sentence)\n",
    "    \n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) # ?.!, 앞뒤로 공백 추가\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence) # 연속된 공백 한개의 공백으로\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^a-zA-Z\\u1100-\\u11FF\\uAC00-\\uD7AF.,?!]\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        왜 지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을...\n",
       "1        길동경찰서입니다 .  시   분 마트에 폭발물을 하나 더 설치할거다 . ? 네 ? ...\n",
       "2        너 되게 귀여운거 알지 ? 나보다 키 작은 남자는 첨봤어 . 그만해 . 니들 놀리는...\n",
       "3        어이 거기 예 ? ? 너 말이야 너 . 너 이리 오라고 무슨 일 . 너 옷 좋아보인...\n",
       "4        저기요 혹시 날이 너무 많이 뜨겁잖아요 ? 저희 회사에서 지금 이 선크림 파는데 한...\n",
       "                               ...                        \n",
       "13543    야 조선생 이것 좀 해와 네 ? 저 부르신건가요 ? 그래 여기 너말고 더 있냐 ? ...\n",
       "13544    나 오늘 진짜 충격 받은 거 있음 뭔데 ? 오늘 근데 뭐 백화점 간다고 안 했냐 응...\n",
       "13545    무제한 요금제 가입했어 ? 아니 . 뭐 ? 엄마가 나 돈 너무 많이 쓴대 . 바보야...\n",
       "13546    야 김대리 너 이리 와봐 장팀장님 부르셨습니까 ? 야 넌 회사 다니는 복장이 그게 ...\n",
       "13547    야 쟤는 오늘도 저 꼴로 왔나봐 아 진짜 미친거같아 한번 오늘도 놀려줄까 ? 저기 ...\n",
       "Name: conversation, Length: 13548, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = train_df['conversation'].apply(preprocess_sentence)\n",
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(conversation, target_vocab_size=2**11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2046\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 1998번째 질문 샘플: [75, 1087, 4, 1469, 889, 50, 1282, 1, 38, 193, 991, 2, 261, 79, 119, 696, 9, 637, 779, 747, 5, 320, 736, 1822, 845, 20, 24, 39, 1012, 7, 77, 323, 98, 1, 242, 493, 501, 1, 131, 110, 845, 20, 148, 329, 110, 1262, 1337, 2, 1087, 696, 1087, 481, 28, 521, 1075, 1, 75, 354, 2027, 1920, 1973, 18, 804, 79, 50, 69, 59, 31, 1, 530, 35, 1, 278, 173, 70, 1370, 50, 462, 1573, 1483, 1822, 845, 12, 1424, 865, 661, 1, 848, 583, 483, 281, 1587, 63, 118, 34, 1, 206, 538, 40, 1301, 1822, 209, 67, 487, 569, 17, 1783, 1822, 827, 42, 131, 189, 102, 17, 787, 6, 845, 338, 486, 42, 117, 1684, 1, 1284, 518, 2, 1526, 61, 82, 199, 1822, 2026, 1931, 1978, 31, 1, 1350, 1, 75, 1159, 55, 90, 62, 805, 316, 1282, 730, 625, 168, 413, 52, 1652, 1, 584, 43, 63, 35, 56]\n"
     ]
    }
   ],
   "source": [
    "# 1998번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 1998번째 질문 샘플: {}'.format(tokenizer.encode(conversation[1998])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그',\n",
       " '학생이',\n",
       " '잠깐',\n",
       " '이리로',\n",
       " '와봐',\n",
       " '.',\n",
       " '왜',\n",
       " '그러시죠',\n",
       " '?',\n",
       " '요즘',\n",
       " '부모들은',\n",
       " '어린',\n",
       " '애들한테도',\n",
       " '명품',\n",
       " '옷을',\n",
       " '좀',\n",
       " '사준다고',\n",
       " '하더니',\n",
       " '.',\n",
       " '진짜였군',\n",
       " '.',\n",
       " '제가',\n",
       " '무슨',\n",
       " '옷을',\n",
       " '입든',\n",
       " '무슨',\n",
       " '상관이에요',\n",
       " '?',\n",
       " '학생들은',\n",
       " '학생답게',\n",
       " '다녀야지',\n",
       " '.',\n",
       " '그',\n",
       " '재킷은',\n",
       " '오늘부로',\n",
       " '내',\n",
       " '거다',\n",
       " '.',\n",
       " '싫어요',\n",
       " '.',\n",
       " '제',\n",
       " '생일선물로',\n",
       " '겨우',\n",
       " '받은',\n",
       " '옷이란',\n",
       " '말이에요',\n",
       " '.',\n",
       " '일을',\n",
       " '복잡하게',\n",
       " '되게',\n",
       " '만드네',\n",
       " '.',\n",
       " '이렇게',\n",
       " '험한',\n",
       " '꼴',\n",
       " '당하고',\n",
       " '싶어',\n",
       " '?',\n",
       " '.',\n",
       " '아뇨',\n",
       " '그치만',\n",
       " '제가',\n",
       " '정말',\n",
       " '많이',\n",
       " '아끼는',\n",
       " '옷인데',\n",
       " '이번만',\n",
       " '봐주시면',\n",
       " '.',\n",
       " '안될까요',\n",
       " '?',\n",
       " '좋아',\n",
       " '그럼',\n",
       " '인심',\n",
       " '썼다',\n",
       " '.',\n",
       " '그럼',\n",
       " '.',\n",
       " '그',\n",
       " '옷',\n",
       " '대신',\n",
       " '만원',\n",
       " '가져와봐',\n",
       " '.',\n",
       " '.',\n",
       " '엄마한테',\n",
       " '문자할게요',\n",
       " '.',\n",
       " '잠시만요',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 확인\n",
    "conversation[1998].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76, 56, 73, 48, 156]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 데이터의 토큰 개수 세기\n",
    "temp = list(map(lambda x : len(x.split()), conversation))\n",
    "temp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 데이터의 토큰 개수 시각화 - histplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_LENGTH = 200 일때: 95.57 %\n",
      "MAX_LENGTH = 100 일때: 69.68 %\n",
      "MAX_LENGTH = 50 일때: 23.05 %\n"
     ]
    }
   ],
   "source": [
    "print(f'MAX_LENGTH = 200 일때: {np.array([True if x <= 200 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')\n",
    "print(f'MAX_LENGTH = 100 일때: {np.array([True if x <= 100 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')\n",
    "print(f'MAX_LENGTH = 50 일때: {np.array([True if x <= 50 else False for x in temp]).sum() / len(conversation) * 100:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 200\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 초과하는 샘플은 데이터 자르기, 패딩\n",
    "def tokenize_and_filter(inputs):\n",
    "  tokenized_inputs = list()\n",
    "  \n",
    "  for sentence in inputs:\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence = tokenizer.encode(sentence)\n",
    "\n",
    "    # 최대 길이 200 까지만 데이터셋으로 사용\n",
    "    if len(sentence) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence)\n",
    "    \n",
    "    else:\n",
    "      tokenized_inputs.append(sentence[:MAX_LENGTH])\n",
    "  \n",
    "  # 최대 길이 200으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 2046\n",
      "필터링 후의 대화 샘플 개수: 13548\n"
     ]
    }
   ],
   "source": [
    "conversation = tokenize_and_filter(conversation)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 대화 샘플 개수: {}'.format(len(conversation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링 - transformer 인코딩 모델 밑바닥부터 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "# 멀티 헤드 어텐션 구현하기\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "# 패딩 마스크 구현 함수\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "# 인코더 생성하기\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더만 구성하기\n",
    "def my_encoder(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"my_encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # Global Average Pooling 적용 (or Max Pooling 가능)\n",
    "  outputs = tf.keras.layers.GlobalMaxPooling1D()(enc_outputs)\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(256, activation=\"relu\", name='dense1')(outputs)\n",
    "#   outputs = tf.keras.layers.Dropout(0.3)(outputs)  # 🔥 드롭아웃 추가 (30%)\n",
    "  outputs = tf.keras.layers.Dense(128, activation=\"relu\", name='dense2')(outputs)\n",
    "#   outputs = tf.keras.layers.Dropout(0.3)(outputs)  # 🔥 드롭아웃 추가 (30%)\n",
    "  outputs = tf.keras.layers.Dense(units=5, activation=\"softmax\", name='outputs')(outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 128)    658432      inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 256)          33024       global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 128)          32896       dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            645         dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 724,997\n",
      "Trainable params: 724,997\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성하기\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 128 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = my_encoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# EarlyStopping & ModelCheckpoint 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"best_model\", monitor='val_loss', save_best_only=True, mode='max', verbose=1, save_format=\"tf\", save_weights_only=True)\n",
    "\n",
    "callbacks = [early_stopping, model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "def get_dataset(data):\n",
    "    conversation = data['conversation'].apply(preprocess_sentence)\n",
    "    conversation = tokenize_and_filter(conversation)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'inputs': conversation},  # 입력 데이터\n",
    "    {'outputs': data['class_encoded'].values}  # 출력 데이터 (라벨)\n",
    "    ))\n",
    "    \n",
    "    dataset = dataset.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_dataset(train_df)\n",
    "val_dataset = get_dataset(val_df)\n",
    "test_dataset = get_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "212/212 [==============================] - 14s 50ms/step - loss: 1.6816 - accuracy: 0.2414 - val_loss: 1.4186 - val_accuracy: 0.3574\n",
      "\n",
      "Epoch 00001: val_loss improved from -inf to 1.41864, saving model to best_model\n",
      "Epoch 2/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 1.6331 - accuracy: 0.2879 - val_loss: 1.3610 - val_accuracy: 0.3781\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.41864\n",
      "Epoch 3/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 1.3723 - accuracy: 0.4406 - val_loss: 0.9364 - val_accuracy: 0.5558\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.41864\n",
      "Epoch 4/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.6318 - accuracy: 0.7821 - val_loss: 0.3187 - val_accuracy: 0.8864\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.41864\n",
      "Epoch 5/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.3032 - accuracy: 0.9032 - val_loss: 0.2233 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.41864\n",
      "Epoch 6/100\n",
      "212/212 [==============================] - 10s 49ms/step - loss: 0.1697 - accuracy: 0.9450 - val_loss: 0.1485 - val_accuracy: 0.9545\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.41864\n",
      "Epoch 7/100\n",
      "212/212 [==============================] - 10s 49ms/step - loss: 0.1331 - accuracy: 0.9570 - val_loss: 0.1333 - val_accuracy: 0.9566\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.41864\n",
      "Epoch 8/100\n",
      "212/212 [==============================] - 10s 49ms/step - loss: 0.1098 - accuracy: 0.9649 - val_loss: 0.0806 - val_accuracy: 0.9793\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.41864\n",
      "Epoch 9/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.0730 - accuracy: 0.9766 - val_loss: 0.0979 - val_accuracy: 0.9793\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.41864\n",
      "Epoch 10/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.0847 - accuracy: 0.9734 - val_loss: 0.1005 - val_accuracy: 0.9773\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.41864\n",
      "Epoch 11/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.0729 - accuracy: 0.9759 - val_loss: 0.1811 - val_accuracy: 0.9628\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.41864\n",
      "Epoch 12/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.0850 - accuracy: 0.9735 - val_loss: 0.0632 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.41864\n",
      "Epoch 13/100\n",
      "212/212 [==============================] - 10s 49ms/step - loss: 0.0439 - accuracy: 0.9882 - val_loss: 0.1935 - val_accuracy: 0.9566\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.41864\n",
      "Epoch 14/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.2012 - accuracy: 0.9457 - val_loss: 0.0855 - val_accuracy: 0.9773\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.41864\n",
      "Epoch 15/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.0447 - accuracy: 0.9879 - val_loss: 0.0919 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.41864\n",
      "Epoch 16/100\n",
      "212/212 [==============================] - 10s 49ms/step - loss: 0.0703 - accuracy: 0.9772 - val_loss: 0.0606 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.41864\n",
      "Epoch 17/100\n",
      "212/212 [==============================] - 10s 49ms/step - loss: 0.0509 - accuracy: 0.9846 - val_loss: 0.1889 - val_accuracy: 0.9628\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.41864\n",
      "Epoch 18/100\n",
      "212/212 [==============================] - 10s 49ms/step - loss: 0.0542 - accuracy: 0.9856 - val_loss: 0.1019 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.41864\n",
      "Epoch 19/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.0677 - accuracy: 0.9799 - val_loss: 0.0767 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.41864\n",
      "Epoch 20/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 0.0875 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.41864\n",
      "Epoch 21/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.0503 - accuracy: 0.9858 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.41864\n",
      "Epoch 22/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 0.0743 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.41864\n",
      "Epoch 23/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.0381 - accuracy: 0.9907 - val_loss: 0.0511 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.41864\n",
      "Epoch 24/100\n",
      "212/212 [==============================] - 10s 48ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.1235 - val_accuracy: 0.9855\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.41864\n",
      "Epoch 25/100\n",
      "212/212 [==============================] - 10s 49ms/step - loss: 0.0362 - accuracy: 0.9914 - val_loss: 0.0178 - val_accuracy: 0.9979\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.41864\n",
      "Epoch 26/100\n",
      "212/212 [==============================] - 10s 49ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.0181 - val_accuracy: 0.9959\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.41864\n",
      "Epoch 00026: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델 학습 실행 (history 저장)\n",
    "EPOCHS = 100\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset, \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# 학습 결과(history) 가져오기\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history.get('accuracy', history.history.get('acc'))  # 'accuracy' 또는 'acc' 키 확인\n",
    "val_acc = history.history.get('val_accuracy', history.history.get('val_acc'))  # 'val_accuracy' 또는 'val_acc' 키 확인\n",
    "\n",
    "# 에포크 값 생성\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Loss 그래프\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2837\n",
       "4    2794\n",
       "2    2722\n",
       "1    2708\n",
       "0    2487\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in train_dataset:\n",
    "    X_train.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_train.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "pd.value_counts(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    106\n",
       "3    100\n",
       "1     98\n",
       "2     93\n",
       "4     87\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in val_dataset:\n",
    "    X_val.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_val.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "pd.value_counts(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    113\n",
       "4     97\n",
       "3     96\n",
       "2     95\n",
       "0     83\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in test_dataset:\n",
    "    X_test.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_test.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "pd.value_counts(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14516, 200)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X 데이터 합치기\n",
    "temp = np.concatenate([X_train, X_val, X_test], axis=0)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14515, 200)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X 데이터 중복값 확인(데이터 누출 확인)\n",
    "np.unique(temp, axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset으로 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 4s 20ms/step - loss: 0.0081 - accuracy: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.008116336539387703, 0.9986714124679565]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (train_dataset을 사용)\n",
    "model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0015 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0015453016385436058, 1.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (validation_dataset을 사용)\n",
    "model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0430 - accuracy: 0.9876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.043026626110076904, 0.9876033067703247]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 (test_dataset을 사용)\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (484, 200)\n",
      "y_test shape: (484,)\n"
     ]
    }
   ],
   "source": [
    "# test_dataset에서 X, y 추출\n",
    "\n",
    "# X와 y 리스트 생성\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# test_dataset에서 inputs(X)와 outputs(y) 추출\n",
    "for x, y in test_dataset:\n",
    "    X_test.extend(x['inputs'].numpy())  # X 값 (입력 데이터)\n",
    "    y_test.extend(y['outputs'].numpy())  # y 값 (라벨 데이터)\n",
    "\n",
    "# 리스트를 NumPy 배열로 변환\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pred(X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "y_pred = get_pred(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9651    1.0000    0.9822        83\n",
      "           1     1.0000    0.9735    0.9865       113\n",
      "           2     0.9895    0.9895    0.9895        95\n",
      "           3     0.9792    0.9792    0.9792        96\n",
      "           4     1.0000    1.0000    1.0000        97\n",
      "\n",
      "    accuracy                         0.9876       484\n",
      "   macro avg     0.9868    0.9884    0.9875       484\n",
      "weighted avg     0.9878    0.9876    0.9876       484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 및 Submission 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1742/4217335460.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_submission_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1742/4217335460.py\u001b[0m in \u001b[0;36mmake_submission_df\u001b[0;34m(model, test_df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_submission_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtest_conversation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest_conversation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_and_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_conversation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_conversation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "def make_submission_df(model, test_df):\n",
    "    test_conversation = test_df['text'].apply(preprocess_sentence)\n",
    "    test_conversation = tokenize_and_filter(test_conversation)\n",
    "    \n",
    "    y_pred = get_pred(test_conversation)\n",
    "    \n",
    "    test_df['target'] = y_pred\n",
    "    test_df.drop(['text'], axis=1, inplace=True)\n",
    "    \n",
    "    return test_df\n",
    "\n",
    "test_df = load_data(test_path)\n",
    "test_df = make_submission_df(model, test_df)\n",
    "test_df.to_csv('my_submission.csv', index=False)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
